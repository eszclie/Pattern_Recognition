{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Transformers_old.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a2da117060db4c1b8019fa3b1666ec57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9921f1de49504f678f55ee646fe8e7e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5a12d91384c402096f6ec70cab87e10","IPY_MODEL_09252e59cd6d4242934d1c29fa18444d"]}},"9921f1de49504f678f55ee646fe8e7e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5a12d91384c402096f6ec70cab87e10":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_75904bbcc7b242a49ada36599f95fdc0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1bc6e54feb1446dbe5b11399ffa4629"}},"09252e59cd6d4242934d1c29fa18444d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ad6390aae6344090bb2dd81f436413f3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:10&lt;00:00, 42.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b065f59d35d14c68a192605052336535"}},"75904bbcc7b242a49ada36599f95fdc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e1bc6e54feb1446dbe5b11399ffa4629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ad6390aae6344090bb2dd81f436413f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b065f59d35d14c68a192605052336535":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72bb8119dc744ef99edcfc6fbb4a0bb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_97fb8942ab2744b289d3f64afce9d1c9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bcd60081fb4545f3a65b91134158e829","IPY_MODEL_ab061f5dc9e9435c983d0330d228a139"]}},"97fb8942ab2744b289d3f64afce9d1c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcd60081fb4545f3a65b91134158e829":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f06ca95891bb4afda31f8845907dcca1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_243b2f02da90477492608d1a05e3598d"}},"ab061f5dc9e9435c983d0330d228a139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e36a751d831e40e984db10c6b09fa5e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 44.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1eb39da401324856a786f1997f127dd4"}},"f06ca95891bb4afda31f8845907dcca1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"243b2f02da90477492608d1a05e3598d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e36a751d831e40e984db10c6b09fa5e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1eb39da401324856a786f1997f127dd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65aaa03eaf0348eba0701638560fd33c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ce2e1bab9a445c1a8f0646a2f906bed","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dd6b9a1d350a45deb4749e717cb7c63f","IPY_MODEL_67d07f079bfa4c1ab8d7fa3d6514e1e7"]}},"4ce2e1bab9a445c1a8f0646a2f906bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd6b9a1d350a45deb4749e717cb7c63f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec3f82d7c5ae408aa2c873add622df0d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_16dae4f10e4547108990e141cd5ffdb5"}},"67d07f079bfa4c1ab8d7fa3d6514e1e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5170238950a046d7b161785c6f7b485d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 793kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c910bace9ffb42e4aaea9bf5c9d9c2cb"}},"ec3f82d7c5ae408aa2c873add622df0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"16dae4f10e4547108990e141cd5ffdb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5170238950a046d7b161785c6f7b485d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c910bace9ffb42e4aaea9bf5c9d9c2cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"dwImbWrenw-L"},"source":["# Mounting drive to save checkpoints there"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SV3cKw2qn1U-","executionInfo":{"status":"ok","timestamp":1611915428403,"user_tz":-60,"elapsed":15611,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"ce19fa19-f1d4-4127-ad55-4806131cc18d"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hSDTzOywZi4X"},"source":["# Transformers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0J87rw9Zh1f","executionInfo":{"status":"ok","timestamp":1611915439029,"user_tz":-60,"elapsed":7065,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"02a61697-c175-46eb-a8dd-cbbe3d81a1f1"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b1/41130a228dd656a1a31ba281598a968320283f48d42782845f6ba567f00b/transformers-4.2.2-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 37.2MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 51.7MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=839591ec95cc1448c706a31487c226488f65d06057baf7e5e3bae38ab7e3913d\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lTdWuZ7PZ-5E","executionInfo":{"status":"ok","timestamp":1611915448365,"user_tz":-60,"elapsed":5210,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["from transformers import BertForSequenceClassification\r\n","from transformers import BertTokenizer\r\n","import torch\r\n","from typing import List\r\n","import random\r\n","import sklearn\r\n","from math import ceil"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"-GUEWgMlfPUR","executionInfo":{"status":"ok","timestamp":1611915450796,"user_tz":-60,"elapsed":949,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["class JudgeBERT(torch.nn.Module):\r\n","  \"\"\"\r\n","  Adds a new head on top of the pre-trained BERT.\r\n","  \"\"\"\r\n","  def __init__(self, freeze_base: bool, device:torch.device):\r\n","    \"\"\"\r\n","    Ctor.\r\n","    :param freeze_base: If True the only the head layers will be trained.\r\n","    \"\"\"\r\n","    torch.nn.Module.__init__(self)\r\n","    self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased').bert\r\n","    self.device = device\r\n","    self.head = torch.nn.Sequential(\r\n","        torch.nn.Linear(in_features=768, out_features=2),\r\n","        torch.nn.Softmax(dim=1)\r\n","    )\r\n","    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n","    if freeze_base:\r\n","      for param in self.bert.parameters():\r\n","        param.requires_grad = False\r\n","  \r\n","  def forward(self, texts: List[str]) -> torch.Tensor:\r\n","    encoding = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\r\n","    y_hat = self.bert(encoding['input_ids'].to(self.device), encoding['attention_mask'].to(self.device))\r\n","    y_hat = self.head(y_hat[1])\r\n","    return y_hat"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyR8OdDcgwqC","executionInfo":{"status":"ok","timestamp":1611915453715,"user_tz":-60,"elapsed":928,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["def train(model: torch.nn.Module, data: List[str], labels: List[str], batch_size: int, optimizer, verbose=False):\r\n","  \"\"\"\r\n","  Trains the network for one epoch.\r\n","  \"\"\"\r\n","  # Set to training mode.\r\n","  model.train(True)\r\n","\r\n","  for start_i in range(0, len(data), batch_size):\r\n","    x = data[start_i:start_i+batch_size]\r\n","    y = labels[start_i:start_i+batch_size]\r\n","    # Convert the labels to torch tensor. Violation is 0, non-violation is 1.\r\n","    y = torch.tensor([0 if l == \"violation\" else 1 for l in y], dtype=torch.long, device=model.device)\r\n","    out = model(x)\r\n","    loss = torch.nn.functional.cross_entropy(input=out, target=y)\r\n","    if verbose:\r\n","      print(f\"loss: {loss.item()}\")\r\n","    optimizer.zero_grad()\r\n","    loss.backward()\r\n","    optimizer.step()\r\n","    optimizer.zero_grad()\r\n","\r\n","\r\n","def test(model: torch.nn.Module, data: List[str], labels: List[str], batch_size: int = 32) -> float:\r\n","  \"\"\"\r\n","  Calculates classification accuracy on the dataset and returns the result.\r\n","  \"\"\"\r\n","  model.train(False)\r\n","  accuracy = 0\r\n","  weight = 0\r\n","  for start_i in range(0, len(data), batch_size):\r\n","    x = data[start_i:start_i+batch_size]\r\n","    y = labels[start_i:start_i+batch_size]\r\n","    weight += len(x)\r\n","    with torch.no_grad():\r\n","      y = torch.tensor([0 if l == \"violation\" else 1 for l in y], dtype=torch.long)\r\n","      y_hat = torch.max(model(x), dim=1)[1].cpu()\r\n","    accuracy += len(x) * sklearn.metrics.accuracy_score(y, y_hat)\r\n","  return accuracy / weight\r\n","\r\n","def save(model, optimizer, epoch):\r\n","  torch.save({\r\n","          'model_state_dict': model.state_dict(),\r\n","          'optimizer_state_dict': optimizer.state_dict(),\r\n","          'epoch': epoch\r\n","      }, f\"/content/drive/My Drive/PR checkpoints/checkpoint_plus.pt\")\r\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hzah2xLSzSes"},"source":["# Loading the data"]},{"cell_type":"code","metadata":{"id":"8_0_sk00zUcj","executionInfo":{"status":"ok","timestamp":1611916465523,"user_tz":-60,"elapsed":7794,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["!unzip -qq crystal_ball_data.zip"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcmXkJO8zd1t","executionInfo":{"status":"ok","timestamp":1611916469535,"user_tz":-60,"elapsed":1120,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["from __future__ import print_function\r\n","import re, glob, sys, time, os, random\r\n","from time import gmtime, strftime\r\n","from sklearn.metrics import accuracy_score\r\n","from sklearn.metrics import recall_score, precision_score, f1_score, classification_report\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.svm import LinearSVC\r\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n","from sklearn.pipeline import Pipeline, FeatureUnion\r\n","import pandas as pd\r\n","import warnings\r\n","from sklearn.model_selection import cross_val_predict, cross_val_score\r\n","from statistics import mean\r\n","from datetime import datetime\r\n","from time import time\r\n","import logging\r\n","from sklearn.feature_extraction.text import CountVectorizer\r\n","from sklearn.feature_extraction.text import TfidfTransformer\r\n","from sklearn.model_selection import GridSearchCV, train_test_split\r\n","from sklearn.pipeline import Pipeline, FeatureUnion\r\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\r\n","import pprint\r\n","from random import shuffle\r\n","\r\n","\r\n","pipeline = Pipeline([\r\n","\t('tfidf', TfidfVectorizer(analyzer='word')),\r\n","\t('clf', LinearSVC())\r\n","])\r\n","\r\n","\r\n","parameters = {\r\n","\t'tfidf__ngram_range': [(1,2),(1,1),(1,3),(1,4),(2,2),(2,3),(2,4),(3,3),(3,4),(4,4)],\r\n","\t#'tfidf__analyzer': ('word', 'char'),\r\n","\t'tfidf__lowercase': (True, False),\r\n","\t#'tfidf__max_df': (0.01, 1.0), # ignore words that occur as more than 1% of corpus\r\n","\t'tfidf__min_df': (1, 2, 3), # we need to see a word at least (once, twice, thrice)\r\n","\t'tfidf__use_idf': (False, True),\r\n","\t#'tfidf__sublinear_tf': (False, True),\r\n","\t'tfidf__binary': (False, True),\r\n","\t'tfidf__norm': (None, 'l1', 'l2'),\r\n","\t#'tfidf__max_features': (None, 2000, 5000),\r\n","\t'tfidf__stop_words': (None, 'english'),\r\n","\r\n","\t#'tfidfchar_ngram_range': ((1,1),(1,2),(1,3),(1,4),(1,5),(1,6),(2,2),(2,3),(2,4),(2,5),(2,6),(3,3),(3,4),(3,5),(3,6),(4,4),(4,5),(4,6),(5,5),(5,6),(1,7),(2,7),(3,7),(4,7),(5,7),(6,7),(7,7)),\r\n","\t\r\n","\t\r\n","\t'clf__C':(0.1, 1, 5)\r\n","}\r\n","\r\n","\r\n","def balance(Xtrain,Ytrain):\r\n","\t#v = Ytrain.count('violation')\r\n","   # nv = Ytrain.count('non-violation')\r\n","\t#print(v, nv)\r\n","\tv = [i for i,val in enumerate(Ytrain) if val=='violation']\r\n","\tnv = [i for i,val in enumerate(Ytrain) if val=='non-violation']\r\n","\tif len(nv) < len(v):\r\n","\t\tv = v[:len(nv)]\r\n","\t\tXtrain = [Xtrain[j] for j in v] + [Xtrain[i] for i in nv]\r\n","\t\tYtrain = [Ytrain[j] for j in v] + [Ytrain[i] for i in nv]\r\n","\tif len(nv) > len(v):\r\n","\t\tnv = nv[:len(v)]\r\n","\t\tXtrain = [Xtrain[j] for j in v] + [Xtrain[i] for i in nv]\r\n","\t\tYtrain = [Ytrain[j] for j in v] + [Ytrain[i] for i in nv]\r\n","\t\r\n","\t#print(Ytrain.count('violation'),Ytrain.count('non-violation'))\r\n","\t#print('LEN', len(Xtrain), len(Ytrain))\r\n","\treturn Xtrain, Ytrain\r\n","\t\r\n","\t\r\n","\r\n","def extract_text(starts, ends, cases, violation):\r\n","\tfacts = []\r\n","\tD = []\r\n","\tyears = []\r\n","\tfor case in cases:\r\n","\t\tcontline = ''\r\n","\t\tyear = 0\r\n","\t\twith open(case, 'r') as f:\r\n","\t\t\tfor line in f:\r\n","\t\t\t\t#print(line)\r\n","\t\t\t\tdat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\r\n","\t\t\t\tif dat != None:\r\n","\t\t\t\t\tyear = int(dat.group(2))\r\n","\t\t\t\t\tbreak\r\n","\t\t\tif year>0:\r\n","\t\t\t\tyears.append(year)\r\n","\t\t\t\t#print(year)\r\n","\t\t\t\twr = 0\r\n","\t\t\t\tfor line in f:\r\n","\t\t\t\t\tif wr == 0:\r\n","\t\t\t\t\t\tif re.search(starts, line) != None:\r\n","\t\t\t\t\t\t\twr = 1\r\n","\t\t\t\t\tif wr == 1 and re.search(ends, line) == None:\r\n","\t\t\t\t\t\tcontline += line\r\n","\t\t\t\t\t\tcontline += '\\n'\r\n","\t\t\t\t\telif re.search(ends, line) != None:\r\n","\t\t\t\t\t\tbreak\r\n","\t\t\t\tfacts.append(contline)\r\n","\tfor i in range(len(facts)):\r\n","\t\tD.append((facts[i], violation, years[i])) \r\n","\treturn D\r\n","\r\n","def extract_parts(article, violation, part, path):\r\n","  # Path is the path to the folder that contains all the text files.\r\n","\tfrom os import listdir\r\n","\tfrom os.path import isfile, join\r\n","\tcases = [join(path, f) for f in listdir(path)]\r\n","\t# cases = glob.glob(path)\r\n","\t#print(cases)\r\n","\r\n","\t\t\r\n","\tfacts = []\r\n","\tD = []\r\n","\tyears = []\r\n","\t\r\n","\tif part == 'relevant_law':\r\n","\t\tfor case in cases:\r\n","\t\t\tyear = 0\r\n","\t\t\tcontline = ''\r\n","\t\t\twith open(case, 'r') as f:\r\n","\t\t\t\tfor line in f:\r\n","\t\t\t\t\tdat = re.search('^([0-9]{1,2}\\s\\w+\\s([0-9]{4}))', line)\r\n","\t\t\t\t\tif dat != None:\r\n","\t\t\t\t\t\t #date = dat.group(1)\r\n","\t\t\t\t\t\tyear = int(dat.group(2))\r\n","\t\t\t\t\t\tbreak\r\n","\t\t\t\tif year> 0:\r\n","\t\t\t\t\tyears.append(year)\r\n","\t\t\t\t\twr = 0\r\n","\t\t\t\t\tfor line in f:\r\n","\t\t\t\t\t\tif wr == 0:\r\n","\t\t\t\t\t\t\tif re.search('RELEVANT', line) != None:\r\n","\t\t\t\t\t\t\t\twr = 1\r\n","\t\t\t\t\t\tif wr == 1 and re.search('THE LAW', line) == None and re.search('PROCEEDINGS', line) == None:\r\n","\t\t\t\t\t\t\tcontline += line\r\n","\t\t\t\t\t\t\tcontline += '\\n'\r\n","\t\t\t\t\t\telif re.search('THE LAW', line) != None or re.search('PROCEEDINGS', line) != None:\r\n","\t\t\t\t\t\t\tbreak\r\n","\t\t\t\t\tfacts.append(contline)\r\n","\t\tfor i in range(len(facts)):\r\n","\t\t\tD.append((facts[i], violation, years[i]))\r\n","\t\t\r\n","\tif part == 'facts':\r\n","\t\tstarts = 'THE FACTS'\r\n","\t\tends ='THE LAW'\r\n","\t\tD = extract_text(starts, ends, cases, violation)\r\n","\tif part == 'circumstances':\r\n","\t\tstarts = 'CIRCUMSTANCES'\r\n","\t\tends ='RELEVANT'\r\n","\t\tD = extract_text(starts, ends, cases, violation)\r\n","\tif part == 'procedure':\r\n","\t\tstarts = 'PROCEDURE'\r\n","\t\tends ='THE FACTS'\r\n","\t\tD = extract_text(starts, ends, cases, violation)\r\n","\tif part == 'procedure+facts':\r\n","\t\tstarts = 'PROCEDURE'\r\n","\t\tends ='THE LAW'\r\n","\t\tD = extract_text(starts, ends, cases, violation)\r\n","\treturn D\r\n","\r\n","\r\n","def fetch(part, path, article):\r\n","  train_v = extract_parts(article, 'violation', part, path+'/train/'+article+'/violation/')\r\n","  train_nv = extract_parts(article, 'non-violation', part, path+'/train/'+article+'/non-violation/')\r\n","  test_v = extract_parts(article, 'violation', part, path+'/test20/'+article+'/violation/')\r\n","  test_nv = extract_parts(article, 'non-violation', part, path+'/test20/'+article+'/non-violation/')\r\n"," \r\n","  return train_v, train_nv, test_v, test_nv\r\n","\r\n","\r\n","def get_facts_dataset(prt, articles: List[int], shuffle: bool = False):\r\n","  \"\"\"\r\n","  Returns a tuple of (training_data, training_labels, test_data, test labels)\r\n","  containing the data from the given articles. The 'data' fields are lists of strings\r\n","  that contain the FACTS part of the cases, while the 'labels' fields are also lists of\r\n","  strings containing either 'violation' or 'non-violation' for their respective data\r\n","  counterparts.\r\n","  :param articles: List of integers of article numbers.\r\n","  :param shuffle: Randomly shuffles the training set if True.\r\n","  \"\"\"\r\n","  path = \"/content/crystal_ball_data\"\r\n","  traind = []\r\n","  trainl = []\r\n","  testd = []\r\n","  testl = []\r\n","  for i in articles:\r\n","    art = f\"Article{i}\"\r\n","    trv, trnv, tev, tenv = fetch(prt, path, art)\r\n","    traind.extend([e[0] for e in trv] + [e[0] for e in trnv])\r\n","    trainl.extend([e[1] for e in trv] + [e[1] for e in trnv])\r\n","\r\n","    testd.extend([e[0] for e in tev] + [e[0] for e in tenv])\r\n","    testl.extend([e[1] for e in tev] + [e[1] for e in tenv])\r\n","  \r\n","  if shuffle:\r\n","    c = list(zip(traind, trainl))\r\n","    random.shuffle(c)\r\n","\r\n","    traind, trainl = zip(*c)\r\n","  \r\n","  return traind, trainl, testd, testl"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j2RC3QDtDitJ"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269,"referenced_widgets":["a2da117060db4c1b8019fa3b1666ec57","9921f1de49504f678f55ee646fe8e7e2","a5a12d91384c402096f6ec70cab87e10","09252e59cd6d4242934d1c29fa18444d","75904bbcc7b242a49ada36599f95fdc0","e1bc6e54feb1446dbe5b11399ffa4629","ad6390aae6344090bb2dd81f436413f3","b065f59d35d14c68a192605052336535","72bb8119dc744ef99edcfc6fbb4a0bb4","97fb8942ab2744b289d3f64afce9d1c9","bcd60081fb4545f3a65b91134158e829","ab061f5dc9e9435c983d0330d228a139","f06ca95891bb4afda31f8845907dcca1","243b2f02da90477492608d1a05e3598d","e36a751d831e40e984db10c6b09fa5e1","1eb39da401324856a786f1997f127dd4","65aaa03eaf0348eba0701638560fd33c","4ce2e1bab9a445c1a8f0646a2f906bed","dd6b9a1d350a45deb4749e717cb7c63f","67d07f079bfa4c1ab8d7fa3d6514e1e7","ec3f82d7c5ae408aa2c873add622df0d","16dae4f10e4547108990e141cd5ffdb5","5170238950a046d7b161785c6f7b485d","c910bace9ffb42e4aaea9bf5c9d9c2cb"]},"id":"he-4jHRgDkpg","executionInfo":{"status":"ok","timestamp":1611916504058,"user_tz":-60,"elapsed":21485,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"121bf5e3-a3d8-478a-a547-45665a7c1cd6"},"source":["jb = JudgeBERT(freeze_base=False, device=torch.device('cuda:0')).to(torch.device(\"cuda:0\"))"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2da117060db4c1b8019fa3b1666ec57","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72bb8119dc744ef99edcfc6fbb4a0bb4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65aaa03eaf0348eba0701638560fd33c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gy32H4U4EOzp","executionInfo":{"status":"ok","timestamp":1611916549655,"user_tz":-60,"elapsed":757,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}}},"source":["optimizer = torch.optim.Adam(params=jb.parameters(), lr=1e-5)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkqpD5fltrT2","executionInfo":{"status":"ok","timestamp":1611916631652,"user_tz":-60,"elapsed":5511,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"1a8e8172-0e5d-40b2-adfa-a12fe8ac80f0"},"source":["import time\r\n","\r\n","t = time.time()\r\n","time.sleep(5)\r\n","duration = time.time() - t\r\n","print(f\"{duration / 60 :.3f} min\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["0.083 min\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"7LvPlqhdHG6P","executionInfo":{"status":"error","timestamp":1611917901067,"user_tz":-60,"elapsed":179175,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"5fb68c6a-6d3d-4ea6-a2a9-962c78e9f024"},"source":["# Training and testing on the following articles:\r\n","article_numbers = [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]\r\n","batch_size = 8\r\n","training_data, training_labels, test_data, test_labels = get_facts_dataset('procedure+facts', article_numbers, shuffle=True)\r\n","\r\n","print(f\"Size of the training data is: {len(training_data)}. Completing an epoch with batch size of {batch_size} will take {ceil(len(training_data) / batch_size)} iterations.\")\r\n","t = time.time()\r\n","acc = test(jb, test_data, test_labels)\r\n","duration = time.time() - t\r\n","print(f\"Duration: {duration / 60 :.3f} min\")\r\n","print(acc)\r\n","for epoch in range(10):\r\n","  train(jb, training_data, training_labels, batch_size=batch_size, optimizer=optimizer, verbose=False)\r\n","  acc = test(jb, test_data, test_labels)\r\n","  save(model=jb, optimizer=optimizer, epoch=epoch+1)\r\n","  print(f\"=== Epoch {epoch+1} completed. ===\")\r\n","  print(f\"| Test accuracy: {acc*100:.3f}%\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Size of the training data is: 3214. Completing an epoch with batch size of 8 will take 402 iterations.\n","Duration: 2.367 min\n","0.6977611940298507\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f059e75cbd50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-77ade493249f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, labels, batch_size, optimizer, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Convert the labels to torch tensor. Violation is 0, non-violation is 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"violation\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-cdf3f37bc9e6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2333\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2335\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2336\u001b[0m             )\n\u001b[1;32m   2337\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2519\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2520\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2521\u001b[0m         )\n\u001b[1;32m   2522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mtokenized_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_on_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_split_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit_on_tokens\u001b[0;34m(tok_list, text)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     (\n\u001b[1;32m    338\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                     )\n\u001b[1;32m    341\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     (\n\u001b[1;32m    338\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenized_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                     )\n\u001b[1;32m    341\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0msplit_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;31m# If the token is part of the never_split set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    410\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_accents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m                         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_strip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/tokenization_bert.py\u001b[0m in \u001b[0;36m_run_strip_accents\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mn\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"b2mDaIa1hpz5"},"source":["# Calcuating precision recall etc"]},{"cell_type":"code","metadata":{"id":"taSHG-_yiOae"},"source":["def get_precision_recall_fscore_single(model: torch.nn.Module, data: List[str], labels: List[str], batch_size: int = 32):\r\n","  model.train(False)\r\n","  prec = 0\r\n","  recall = 0\r\n","  fscore = 0\r\n","  weight = 0\r\n","  for start_i in range(0, len(data), batch_size):\r\n","    x = data[start_i:start_i+batch_size]\r\n","    y = labels[start_i:start_i+batch_size]\r\n","    weight += len(x)\r\n","    with torch.no_grad():\r\n","      y = torch.tensor([0 if l == \"violation\" else 1 for l in y], dtype=torch.long)\r\n","      y_hat = torch.max(model(x), dim=1)[1].cpu()\r\n","    p, r, f, _ = sklearn.metrics.precision_recall_fscore_support(y, y_hat)\r\n","    prec += len(x) * p\r\n","    recall += len(x) * r\r\n","    fscore = len(x) * f\r\n","  return prec / weight, recall / weight, fscore / weight\r\n","\r\n","def get_precision_recall_fscore(prt, model, article_numbers) -> dict:\r\n","  \"\"\"\r\n","  Call this function to obtain per article network performance.\r\n","  It returns a dict with the article numbers as keys, and another dict\r\n","  as value, which contains 3 keys: {'precision', 'recall', 'f-score'}.\r\n","  \"\"\"\r\n","  stats = dict()\r\n","  for i in article_numbers:\r\n","    _, _, test_data, test_labels = get_facts_dataset(prt, [i], shuffle=False)\r\n","    if i == 6:\r\n","      print(test_labels)\r\n","    p, r, f = get_precision_recall_fscore_single(model, test_data, test_labels)\r\n","    acc = test(jb, test_data, test_labels)\r\n","    print(f\"acc {i}: {acc:.3f}\")\r\n","    stats[i] = {\"precision\": p, \"recall\": r, \"f-score\": f}\r\n","  return stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOTdbW8rht1_","executionInfo":{"status":"ok","timestamp":1611841162409,"user_tz":-60,"elapsed":263029,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"b15ed1eb-668a-4e5b-da4f-58168ad2d18d"},"source":["# Path to the saved checkpoint. Replace with yours.\r\n","# Alternatively comment the whole loadin thing out in case you just\r\n","# finished training, and the network is still in memory.\r\n","\r\n","article_numbers = [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18]\r\n","training_data, training_labels, test_data, test_labels = get_facts_dataset('facts', article_numbers, shuffle=True)\r\n","\r\n","path = f\"/content/drive/My Drive/PR checkpoints/checkpoint_e10.pt\"\r\n","ckpt = torch.load(path)\r\n","print(\"Checkpoint loaded.\")\r\n","\r\n","jb.load_state_dict(ckpt[\"model_state_dict\"])\r\n","print(\"Network parameters loaded.\")\r\n","\r\n","\r\n","# acc = test(jb, test_data, test_labels)\r\n","# print(f\"| Test accuracy: {acc*100:.3f}%\")\r\n","eval_stats = get_precision_recall_fscore('facts', jb, [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["acc 2: 0.929\n","acc 3: 0.754\n","acc 4: 1.000\n","acc 5: 0.737\n","['violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation', 'non-violation']\n","acc 6: 0.776\n","acc 7: 0.583\n","acc 8: 0.772\n","acc 10: 0.722\n","acc 11: 0.812\n","acc 12: 0.500\n","acc 13: 0.796\n","acc 14: 0.653\n","acc 18: 1.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1Py_GQjj2bM","executionInfo":{"status":"ok","timestamp":1611839951105,"user_tz":-60,"elapsed":917,"user":{"displayName":"Bendeguz Toth","photoUrl":"","userId":"02054990165678012572"}},"outputId":"63b55d4b-5d69-4cc3-f0d4-969ddeabe755"},"source":["# Here is how to inspect the results. Prints the results of article 10.\r\n","# Notice that there are two values: the fist value is for violation,\r\n","# the second value is for non-violation.\r\n","print(eval_stats[2])\r\n","\r\n","print(\"               PRECISION        RECALL    F-SCORE\")\r\n","for k in eval_stats.keys():\r\n","  # print(eval_stats[k])\r\n","  print(f\"Art {k}   non-violation: {eval_stats[k]['precision'][1]:.2f}  {eval_stats[k]['recall'][1]:.2f}  {eval_stats[k]['f-score'][1]:.2f}\")\r\n","  print(f\"Art {k}   violation: {eval_stats[k]['precision'][0]:.2f}  {eval_stats[k]['recall'][0]:.2f}  {eval_stats[k]['f-score'][0]:.2f}\")\r\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'precision': array([1.   , 0.875]), 'recall': array([0.85714286, 1.        ]), 'f-score': array([0.92307692, 0.93333333])}\n","               PRECISION        RECALL    F-SCORE\n","Art 2   non-violation: 0.88  1.00  0.93\n","Art 2   violation: 1.00  0.86  0.92\n","\n","Art 3   non-violation: 0.52  0.41  0.08\n","Art 3   violation: 0.56  0.48  0.00\n","\n","Art 4   non-violation: 1.00  1.00  1.00\n","Art 4   violation: 1.00  1.00  1.00\n","\n","Art 5   non-violation: 0.55  0.39  0.14\n","Art 5   violation: 0.56  0.68  0.00\n","\n","Art 6   non-violation: 0.55  0.42  0.01\n","Art 6   violation: 0.54  0.47  0.00\n","\n","Art 7   non-violation: 0.57  0.67  0.62\n","Art 7   violation: 0.60  0.50  0.55\n","\n","Art 8   non-violation: 0.53  0.63  0.14\n","Art 8   violation: 0.54  0.37  0.00\n","\n","Art 10   non-violation: 0.58  0.94  0.38\n","Art 10   violation: 0.59  0.33  0.00\n","\n","Art 11   non-violation: 0.86  0.75  0.80\n","Art 11   violation: 0.78  0.88  0.82\n","\n","Art 12   non-violation: 0.50  1.00  0.67\n","Art 12   violation: 0.00  0.00  0.00\n","\n","Art 13   non-violation: 0.70  0.77  0.34\n","Art 13   violation: 0.57  0.50  0.00\n","\n","Art 14   non-violation: 0.52  0.40  0.09\n","Art 14   violation: 0.54  0.49  0.00\n","\n","Art 18   non-violation: 1.00  1.00  1.00\n","Art 18   violation: 1.00  1.00  1.00\n","\n"],"name":"stdout"}]}]}